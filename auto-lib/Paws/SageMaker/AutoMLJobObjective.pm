# Generated by default/object.tt
package Paws::SageMaker::AutoMLJobObjective;
  use Moose;
  has MetricName => (is => 'ro', isa => 'Str', required => 1);

1;

### main pod documentation begin ###

=head1 NAME

Paws::SageMaker::AutoMLJobObjective

=head1 USAGE

This class represents one of two things:

=head3 Arguments in a call to a service

Use the attributes of this class as arguments to methods. You shouldn't make instances of this class. 
Each attribute should be used as a named argument in the calls that expect this type of object.

As an example, if Att1 is expected to be a Paws::SageMaker::AutoMLJobObjective object:

  $service_obj->Method(Att1 => { MetricName => $value, ..., MetricName => $value  });

=head3 Results returned from an API call

Use accessors for each attribute. If Att1 is expected to be an Paws::SageMaker::AutoMLJobObjective object:

  $result = $service_obj->Method(...);
  $result->Att1->MetricName

=head1 DESCRIPTION

Specifies a metric to minimize or maximize as the objective of an
AutoML job.

=head1 ATTRIBUTES


=head2 B<REQUIRED> MetricName => Str

The name of the objective metric used to measure the predictive quality
of a machine learning system. During training, the model's parameters
are updated iteratively to optimize its performance based on the
feedback provided by the objective metric when evaluating the model on
the validation dataset.

The list of available metrics supported by Autopilot and the default
metric applied when you do not specify a metric name explicitly depend
on the problem type.

=over

=item *

For tabular problem types:

=over

=item *

List of available metrics:

=over

=item *

Regression: C<MAE>, C<MSE>, C<R2>, C<RMSE>

=item *

Binary classification: C<Accuracy>, C<AUC>, C<BalancedAccuracy>, C<F1>,
C<Precision>, C<Recall>

=item *

Multiclass classification: C<Accuracy>, C<BalancedAccuracy>,
C<F1macro>, C<PrecisionMacro>, C<RecallMacro>

=back

For a description of each metric, see Autopilot metrics for
classification and regression
(https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-metrics-validation.html#autopilot-metrics).

=item *

Default objective metrics:

=over

=item *

Regression: C<MSE>.

=item *

Binary classification: C<F1>.

=item *

Multiclass classification: C<Accuracy>.

=back

=back

=item *

For image or text classification problem types:

=over

=item *

List of available metrics: C<Accuracy>

For a description of each metric, see Autopilot metrics for text and
image classification
(https://docs.aws.amazon.com/sagemaker/latest/dg/text-classification-data-format-and-metric.html).

=item *

Default objective metrics: C<Accuracy>

=back

=item *

For time-series forecasting problem types:

=over

=item *

List of available metrics: C<RMSE>, C<wQL>, C<Average wQL>, C<MASE>,
C<MAPE>, C<WAPE>

For a description of each metric, see Autopilot metrics for time-series
forecasting
(https://docs.aws.amazon.com/sagemaker/latest/dg/timeseries-objective-metric.html).

=item *

Default objective metrics: C<AverageWeightedQuantileLoss>

=back

=item *

For text generation problem types (LLMs fine-tuning): Fine-tuning
language models in Autopilot does not require setting the
C<AutoMLJobObjective> field. Autopilot fine-tunes LLMs without
requiring multiple candidates to be trained and evaluated. Instead,
using your dataset, Autopilot directly fine-tunes your target model to
enhance a default objective metric, the cross-entropy loss. After
fine-tuning a language model, you can evaluate the quality of its
generated text using different metrics. For a list of the available
metrics, see Metrics for fine-tuning LLMs in Autopilot
(https://docs.aws.amazon.com/sagemaker/latest/dg/autopilot-llms-finetuning-metrics.html).

=back




=head1 SEE ALSO

This class forms part of L<Paws>, describing an object used in L<Paws::SageMaker>

=head1 BUGS and CONTRIBUTIONS

The source code is located here: L<https://github.com/pplu/aws-sdk-perl>

Please report bugs to: L<https://github.com/pplu/aws-sdk-perl/issues>

=cut

