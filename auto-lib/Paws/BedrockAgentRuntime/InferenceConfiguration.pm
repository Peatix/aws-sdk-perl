# Generated by default/object.tt
package Paws::BedrockAgentRuntime::InferenceConfiguration;
  use Moose;
  has MaximumLength => (is => 'ro', isa => 'Int', request_name => 'maximumLength', traits => ['NameInRequest']);
  has StopSequences => (is => 'ro', isa => 'ArrayRef[Str|Undef]', request_name => 'stopSequences', traits => ['NameInRequest']);
  has Temperature => (is => 'ro', isa => 'Num', request_name => 'temperature', traits => ['NameInRequest']);
  has TopK => (is => 'ro', isa => 'Int', request_name => 'topK', traits => ['NameInRequest']);
  has TopP => (is => 'ro', isa => 'Num', request_name => 'topP', traits => ['NameInRequest']);

1;

### main pod documentation begin ###

=head1 NAME

Paws::BedrockAgentRuntime::InferenceConfiguration

=head1 USAGE

This class represents one of two things:

=head3 Arguments in a call to a service

Use the attributes of this class as arguments to methods. You shouldn't make instances of this class. 
Each attribute should be used as a named argument in the calls that expect this type of object.

As an example, if Att1 is expected to be a Paws::BedrockAgentRuntime::InferenceConfiguration object:

  $service_obj->Method(Att1 => { MaximumLength => $value, ..., TopP => $value  });

=head3 Results returned from an API call

Use accessors for each attribute. If Att1 is expected to be an Paws::BedrockAgentRuntime::InferenceConfiguration object:

  $result = $service_obj->Method(...);
  $result->Att1->MaximumLength

=head1 DESCRIPTION

Specifications about the inference parameters that were provided
alongside the prompt. These are specified in the
PromptOverrideConfiguration
(https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent_PromptOverrideConfiguration.html)
object that was set when the agent was created or updated. For more
information, see Inference parameters for foundation models
(https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html).

=head1 ATTRIBUTES


=head2 MaximumLength => Int

The maximum number of tokens allowed in the generated response.


=head2 StopSequences => ArrayRef[Str|Undef]

A list of stop sequences. A stop sequence is a sequence of characters
that causes the model to stop generating the response.


=head2 Temperature => Num

The likelihood of the model selecting higher-probability options while
generating a response. A lower value makes the model more likely to
choose higher-probability options, while a higher value makes the model
more likely to choose lower-probability options.


=head2 TopK => Int

While generating a response, the model determines the probability of
the following token at each point of generation. The value that you set
for C<topK> is the number of most-likely candidates from which the
model chooses the next token in the sequence. For example, if you set
C<topK> to 50, the model selects the next token from among the top 50
most likely choices.


=head2 TopP => Num

While generating a response, the model determines the probability of
the following token at each point of generation. The value that you set
for C<Top P> determines the number of most-likely candidates from which
the model chooses the next token in the sequence. For example, if you
set C<topP> to 0.8, the model only selects the next token from the top
80% of the probability distribution of next tokens.



=head1 SEE ALSO

This class forms part of L<Paws>, describing an object used in L<Paws::BedrockAgentRuntime>

=head1 BUGS and CONTRIBUTIONS

The source code is located here: L<https://github.com/pplu/aws-sdk-perl>

Please report bugs to: L<https://github.com/pplu/aws-sdk-perl/issues>

=cut

