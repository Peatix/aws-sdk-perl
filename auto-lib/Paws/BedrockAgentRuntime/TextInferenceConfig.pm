# Generated by default/object.tt
package Paws::BedrockAgentRuntime::TextInferenceConfig;
  use Moose;
  has MaxTokens => (is => 'ro', isa => 'Int', request_name => 'maxTokens', traits => ['NameInRequest']);
  has StopSequences => (is => 'ro', isa => 'ArrayRef[Str|Undef]', request_name => 'stopSequences', traits => ['NameInRequest']);
  has Temperature => (is => 'ro', isa => 'Num', request_name => 'temperature', traits => ['NameInRequest']);
  has TopP => (is => 'ro', isa => 'Num', request_name => 'topP', traits => ['NameInRequest']);

1;

### main pod documentation begin ###

=head1 NAME

Paws::BedrockAgentRuntime::TextInferenceConfig

=head1 USAGE

This class represents one of two things:

=head3 Arguments in a call to a service

Use the attributes of this class as arguments to methods. You shouldn't make instances of this class. 
Each attribute should be used as a named argument in the calls that expect this type of object.

As an example, if Att1 is expected to be a Paws::BedrockAgentRuntime::TextInferenceConfig object:

  $service_obj->Method(Att1 => { MaxTokens => $value, ..., TopP => $value  });

=head3 Results returned from an API call

Use accessors for each attribute. If Att1 is expected to be an Paws::BedrockAgentRuntime::TextInferenceConfig object:

  $result = $service_obj->Method(...);
  $result->Att1->MaxTokens

=head1 DESCRIPTION

Configuration settings for text generation using a language model via
the RetrieveAndGenerate operation. Includes parameters like
temperature, top-p, maximum token count, and stop sequences.

The valid range of C<maxTokens> depends on the accepted values for your
chosen model's inference parameters. To see the inference parameters
for your model, see Inference parameters for foundation models.
(https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html)

=head1 ATTRIBUTES


=head2 MaxTokens => Int

The maximum number of tokens to generate in the output text. Do not use
the minimum of 0 or the maximum of 65536. The limit values described
here are arbitary values, for actual values consult the limits defined
by your specific model.


=head2 StopSequences => ArrayRef[Str|Undef]

A list of sequences of characters that, if generated, will cause the
model to stop generating further tokens. Do not use a minimum length of
1 or a maximum length of 1000. The limit values described here are
arbitary values, for actual values consult the limits defined by your
specific model.


=head2 Temperature => Num

Controls the random-ness of text generated by the language model,
influencing how much the model sticks to the most predictable next
words versus exploring more surprising options. A lower temperature
value (e.g. 0.2 or 0.3) makes model outputs more deterministic or
predictable, while a higher temperature (e.g. 0.8 or 0.9) makes the
outputs more creative or unpredictable.


=head2 TopP => Num

A probability distribution threshold which controls what the model
considers for the set of possible next tokens. The model will only
consider the top p% of the probability distribution when generating the
next token.



=head1 SEE ALSO

This class forms part of L<Paws>, describing an object used in L<Paws::BedrockAgentRuntime>

=head1 BUGS and CONTRIBUTIONS

The source code is located here: L<https://github.com/pplu/aws-sdk-perl>

Please report bugs to: L<https://github.com/pplu/aws-sdk-perl/issues>

=cut

